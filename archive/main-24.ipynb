{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sid/miniconda3/envs/cnt/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import random\n",
    "import string\n",
    "\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import RobertaConfig, RobertaForMaskedLM, RobertaTokenizer\n",
    "from transformers.modeling_outputs import MaskedLMOutput\n",
    "from tokenizers import normalizers\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\"\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLS = \"<cls>\"\n",
    "EOS = \"<eos>\"\n",
    "CHAR_PAD = \"<char_pad>\"\n",
    "UNK = \"<unk>\"\n",
    "NGRAM_PAD = \"<ngram_pad>\"\n",
    "MASK = \"<mask>\"\n",
    "\n",
    "SPECIAL_CHARS = {\n",
    "    CLS,\n",
    "    EOS,\n",
    "    CHAR_PAD,\n",
    "    UNK,\n",
    "    NGRAM_PAD,\n",
    "    MASK,\n",
    "}\n",
    "CHAR_TOKENS: list[str] = sorted(list(string.printable) + list(SPECIAL_CHARS))\n",
    "NGRAM_SIZE: int = 8\n",
    "NUM_ATTENTION_HEADS: int = 12\n",
    "HIDDEN_SIZE: int = 1536  # multiple of NUM_ATTENTION_HEADS, 768 default\n",
    "MAX_SEQ_LEN: int = NGRAM_SIZE * 20  # multiple of NGRAM_SIZE\n",
    "PROB_MASK: float = 0.15\n",
    "\n",
    "\n",
    "num_chars = len(CHAR_TOKENS)\n",
    "char_to_idx = {c: i for i, c in enumerate(CHAR_TOKENS)}\n",
    "idx_to_char = {i: c for i, c in enumerate(CHAR_TOKENS)}\n",
    "\n",
    "normalizer = normalizers.Sequence(\n",
    "    [normalizers.NFD(), normalizers.Lowercase(), normalizers.StripAccents()]\n",
    ")\n",
    "\n",
    "\n",
    "def tokenize(seq: str):\n",
    "    seq = normalizer.normalize_str(seq)\n",
    "    seq = [CLS] + list(seq)\n",
    "    # Pad such that len(seq) is divisible by NGRAM_SIZE\n",
    "    if len(seq) % NGRAM_SIZE > 0:\n",
    "        seq += [CHAR_PAD] * (NGRAM_SIZE - (len(seq) % NGRAM_SIZE))\n",
    "    seq += [EOS] * NGRAM_SIZE\n",
    "    return torch.tensor(\n",
    "        [char_to_idx[c] if c in char_to_idx else char_to_idx[UNK] for c in seq]\n",
    "    )\n",
    "\n",
    "\n",
    "def collate(tokenized_seqs: list[torch.tensor], masking_probability: float = PROB_MASK):\n",
    "    \"\"\"Pad short seqs, truncate long seqs.\"\"\"\n",
    "    tokenized_seqs = [x[:MAX_SEQ_LEN] for x in tokenized_seqs]\n",
    "    max_len = max(x.shape[-1] for x in tokenized_seqs)\n",
    "    labels = torch.full(\n",
    "        size=[len(tokenized_seqs), max_len],\n",
    "        fill_value=char_to_idx[NGRAM_PAD],\n",
    "        dtype=torch.long,\n",
    "    )\n",
    "    attention_mask = torch.ones_like(labels)\n",
    "    for i, x in enumerate(tokenized_seqs):\n",
    "        labels[i, 0 : len(x)] = x\n",
    "        attention_mask[i, len(x) :] = 0\n",
    "    # Masking, on ngram level rather than char\n",
    "    masked_labels = labels.clone().detach()\n",
    "    for row_idx in range(masked_labels.shape[0]):\n",
    "        for ngram_idx in range(0, masked_labels.shape[1], NGRAM_SIZE):\n",
    "            if random.random() < masking_probability:\n",
    "                masked_labels[row_idx, ngram_idx : ngram_idx + NGRAM_SIZE] = char_to_idx[\n",
    "                    MASK\n",
    "                ]\n",
    "    return {\n",
    "        \"labels\": labels,\n",
    "        \"masked_labels\": masked_labels,\n",
    "        \"attention_mask\": attention_mask,\n",
    "    }\n",
    "\n",
    "\n",
    "# example_data = [\"Hi..\", \"This is a second sentence.\"]\n",
    "# example_data_tokenized = collate([tokenize(s) for s in example_data])\n",
    "# print(example_data_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wikipedia (/media/bigdata/datasets/wikipedia/20220301.en/2.0.0/aa542ed919df55cc5d3347f42dd4521d05ca68751f50dbc32bae2a7f1e167559)\n",
      "Found cached dataset wikipedia (/media/bigdata/datasets/wikipedia/20220301.en/2.0.0/aa542ed919df55cc5d3347f42dd4521d05ca68751f50dbc32bae2a7f1e167559)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800000\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, split):\n",
    "        self.examples = load_dataset(\n",
    "            \"wikipedia\",\n",
    "            \"20220301.en\",\n",
    "            split=split,\n",
    "            cache_dir=\"/media/bigdata/datasets/\",\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        text = self.examples[i][\"text\"]\n",
    "        if not type(text) == str:\n",
    "            text = \"\"\n",
    "        return tokenize(text)\n",
    "\n",
    "\n",
    "dataset_train = MyDataset(split=\"train[:800000]\")\n",
    "dataset_eval = MyDataset(split=\"train[-100:]\")\n",
    "print(len(dataset_train))\n",
    "print(len(dataset_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-16 21:33:52,986 Starting new HTTPS connection (1): huggingface.co:443\n",
      "2023-03-16 21:33:53,658 https://huggingface.co:443 \"GET /api/datasets/wikipedia HTTP/1.1\" 200 13760\n",
      "2023-03-16 21:33:53,663 Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
      "2023-03-16 21:33:54,171 https://s3.amazonaws.com:443 \"HEAD /datasets.huggingface.co/datasets/datasets/wikipedia/wikipedia.py HTTP/1.1\" 200 0\n",
      "2023-03-16 21:33:54,178 Starting new HTTPS connection (1): huggingface.co:443\n",
      "2023-03-16 21:33:54,580 https://huggingface.co:443 \"HEAD /datasets/wikipedia/resolve/main/wikipedia.py HTTP/1.1\" 200 0\n",
      "2023-03-16 21:33:54,589 Starting new HTTPS connection (1): huggingface.co:443\n",
      "2023-03-16 21:33:54,991 https://huggingface.co:443 \"HEAD /datasets/wikipedia/resolve/main/dataset_infos.json HTTP/1.1\" 200 0\n",
      "2023-03-16 21:33:54,998 Starting new HTTPS connection (1): huggingface.co:443\n",
      "2023-03-16 21:33:55,412 https://huggingface.co:443 \"HEAD /datasets/wikipedia/resolve/main/README.md HTTP/1.1\" 200 0\n",
      "2023-03-16 21:33:55,477 open file: /media/bigdata/datasets/wikipedia/20220301.en/2.0.0/aa542ed919df55cc5d3347f42dd4521d05ca68751f50dbc32bae2a7f1e167559/dataset_info.json\n",
      "2023-03-16 21:33:55,498 Found cached dataset wikipedia (/media/bigdata/datasets/wikipedia/20220301.en/2.0.0/aa542ed919df55cc5d3347f42dd4521d05ca68751f50dbc32bae2a7f1e167559)\n",
      "2023-03-16 21:33:55,499 open file: /media/bigdata/datasets/wikipedia/20220301.en/2.0.0/aa542ed919df55cc5d3347f42dd4521d05ca68751f50dbc32bae2a7f1e167559/dataset_info.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6458670"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(load_dataset(\n",
    "    \"wikipedia\",\n",
    "    \"20220301.en\",\n",
    "    split=\"train\",\n",
    "    cache_dir=\"/media/bigdata/datasets/\",\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0733375"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6_458_670/800_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # An embedding table for each slot in the the ngram, (e.g. 0, 1, 2 for a NGRAM_SIZE=3).\n",
    "        self.ngram_embedding_tables = [\n",
    "            torch.nn.Embedding(\n",
    "                num_embeddings=num_chars,\n",
    "                embedding_dim=HIDDEN_SIZE,\n",
    "                padding_idx=char_to_idx[NGRAM_PAD],\n",
    "            )\n",
    "            for _ in range(NGRAM_SIZE)\n",
    "        ]\n",
    "        self.language_model = RobertaForMaskedLM(\n",
    "            config=RobertaConfig(\n",
    "                vocab_size=2,  # won't use\n",
    "                hidden_size=HIDDEN_SIZE,  # default 768\n",
    "                max_position_embeddings=514,\n",
    "                num_attention_heads=NUM_ATTENTION_HEADS,\n",
    "                num_hidden_layers=6,\n",
    "                type_vocab_size=1,\n",
    "                attention_probs_dropout_prob=0,\n",
    "                hidden_dropout_prob=0,\n",
    "            )\n",
    "        )\n",
    "        # To map from the lm embeddings back to the chars\n",
    "        self.ngram_prediction_heads = [\n",
    "            torch.nn.Linear(HIDDEN_SIZE, num_chars) for _ in range(NGRAM_SIZE)\n",
    "        ]\n",
    "\n",
    "    def forward(self, labels, masked_labels, attention_mask):\n",
    "        logits = self.predict(masked_labels, attention_mask)[0]\n",
    "        loss = self.get_loss(logits, labels)\n",
    "        return MaskedLMOutput(loss=loss, logits=logits)\n",
    "\n",
    "    def predict(self, labels, attention_mask):\n",
    "        input_embeddings = self.get_input_embeddings(labels)\n",
    "        lm_embeddings = self.language_model.roberta.forward(\n",
    "            inputs_embeds=input_embeddings,\n",
    "            attention_mask=attention_mask[:, ::NGRAM_SIZE],\n",
    "        ).last_hidden_state\n",
    "        logits = self.get_predicted_char_logits(lm_embeddings)\n",
    "        return logits, lm_embeddings, input_embeddings\n",
    "\n",
    "    def get_loss(self, logits, labels):\n",
    "        return torch.nn.functional.cross_entropy(\n",
    "            logits.reshape(-1, num_chars), labels.reshape(-1)\n",
    "        )\n",
    "\n",
    "    def get_input_embeddings(self, x_batch: torch.tensor):\n",
    "        result = []\n",
    "        for ngram_slot_idx in range(NGRAM_SIZE):\n",
    "            ngram_slot_embeddings = self.ngram_embedding_tables[ngram_slot_idx](\n",
    "                x_batch[:, ngram_slot_idx::NGRAM_SIZE]\n",
    "            )\n",
    "            result.append(ngram_slot_embeddings)\n",
    "        result = torch.stack(result).sum(dim=0)\n",
    "        return result\n",
    "\n",
    "    def get_predicted_char_logits(self, xbatch_lm_embeddings: torch.tensor):\n",
    "        \"\"\"Map from the lm embeddings back to the chars\"\"\"\n",
    "        result = []\n",
    "        for ngram_slot_idx in range(NGRAM_SIZE):\n",
    "            predicted_char = self.ngram_prediction_heads[ngram_slot_idx](\n",
    "                xbatch_lm_embeddings\n",
    "            )\n",
    "            result.append(predicted_char)\n",
    "        result = torch.concatenate(result, dim=1)\n",
    "        return result\n",
    "\n",
    "    def to(self, *args, **kwargs):\n",
    "        for x in self.ngram_embedding_tables:\n",
    "            x.to(*args, **kwargs)\n",
    "        self.language_model.to(*args, **kwargs)\n",
    "        for x in self.ngram_prediction_heads:\n",
    "            x.to(*args, **kwargs)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CharModel()\n",
    "# logits = model.predict(\n",
    "#     example_data_tokenized[\"labels\"], example_data_tokenized[\"attention_mask\"]\n",
    "# )[0]\n",
    "# loss = model.get_loss(logits, example_data_tokenized[\"labels\"])\n",
    "\n",
    "# print(example_data_tokenized[\"labels\"].shape)\n",
    "# print(logits.shape)\n",
    "# print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(labels):\n",
    "    # To convert back to text\n",
    "    predicted_sentences = []\n",
    "    for sentence_ids in labels:\n",
    "        # chars = [idx_to_char[i] for i in sentence_ids]\n",
    "        # chars = [c for i, c in enumerate(chars) if i > 0 and not c == chars[i - 1]]\n",
    "        chars = []\n",
    "        for i in sentence_ids:\n",
    "            char = idx_to_char[i]\n",
    "            # `char in chars[-1:]` is to compare to the last char,\n",
    "            # that also works when there are no no chars..\n",
    "            if char in SPECIAL_CHARS and char in chars[-1:]:\n",
    "                continue\n",
    "            chars.append(char)\n",
    "        predicted_sentences.append(\"\".join(chars))\n",
    "    return predicted_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./data/hf_trainer/\",\n",
    "    logging_dir=\"./data/hf_trainer/runs\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=64,\n",
    "    save_steps=5000,\n",
    "    learning_rate=5e-5,  # defaults to 5e-5\n",
    "    # logging_steps=5000,\n",
    "    save_total_limit=2,\n",
    "    prediction_loss_only=True,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=collate,\n",
    "    train_dataset=dataset_train,\n",
    "    # eval_dataset=dataset_eval,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, format=\"%(asctime)s %(message)s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sid/miniconda3/envs/cnt/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 800000\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12500\n",
      "  Number of trainable parameters = 116508674\n",
      "  Num examples = 800000\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12500\n",
      "  Number of trainable parameters = 116508674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./data/hf_trainer/checkpoint-5000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ./data/hf_trainer/checkpoint-10000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "torch.save(model.state_dict(), \"./data/model.torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- dataset 0 ---\n",
      "\n",
      "['<cls>anarchism is a political philosophy and movement that is sceptical of authority and rejects all involuntary, coercive forms of hierarchy. anarchism calls for t']\n",
      "['<cls>anarchism is a political philosophy and movemen<mask>s sceptical of authority and rejects all<mask>tary, coercive forms of hierarchy. anarchism calls for t']\n",
      "['<cls>anarchism is a political philosophy and movemens   l   s sceptical of authority and rerects alltoe     tary, coercive forms of hierarchy. anarchism calls for t']\n",
      "\n",
      "['<cls>autism is a neurodevelopmental disorder characterized by difficulties with social interaction and communication, and by restricted and repetitive behavior. par']\n",
      "['<mask>is a neurodevelopmental disorder characterized by difficulties with social interaction a<mask>nication<mask> restricted and repetitive behavior. par']\n",
      "['<cls>the e iis a neurodevelopmental disorder characterined by difficulties with social interaction ate      nication  o    r restricted and repetitive behavior. par']\n",
      "\n",
      "['<cls>albedo (; ) is the measure of the diffuse reflection of solar radiation out of the total solar radiation and measured on a scale from 0, corresponding to a bla']\n",
      "['<mask>(; ) is the measure of the diffuse reflection of solar radiation out of the total solar radiation and measured o<mask>e from 0, corresponding to a bla']\n",
      "['<cls>the io (( ) is the measure of the difffse reflection of solar radiation out of the total solar radiation and measured or  ti  oe from m, corresponding to a bla']\n",
      "\n",
      "['<cls>a, or a, is the first letter and the first vowel of the modern english alphabet and the iso basic latin alphabet. its name in english is a (pronounced ), plura']\n",
      "['<cls>a, or a, is the first letter and the first vowel of the<mask>alphabet and the iso bas<mask>t. its name in english i<mask>nounced <mask>']\n",
      "['<cls>a, or a, is the first letter and the first vowel of the  i    te  ee   alphabet and the iso basee   n ee       t. its name in english ih       nounced s       ']\n",
      "\n",
      "['<cls>alabama () is a state in the southeastern region of the united states, bordered by tennessee to the north; georgia to the east; florida and the gulf of mexico ']\n",
      "['<cls>alabama () is a state in the southeastern region of the united states, bordered by tennessee to the nor<mask>gia to t<mask> florida and the gulf of<mask>']\n",
      "['<cls>alabama () is a state in the southeastern region of the united states, bordered by tennessee to the nor    n  ngia to t      ad florida and the gulf of   e   e']\n",
      "\n",
      "[\"<cls>in greek mythology, achilles ( ) or achilleus () was a hero of the trojan war, the greatest of all the greek warriors, and is the central character of homer's \"]\n",
      "[\"<mask>k mythology, achilles ( ) or ach<mask>) was a hero of the trojan war, <mask>test of all the greek warriors, <mask>he central character of homer's \"]\n",
      "['<cls>tn  re y mythology, achilles ( ) or achaa      ) was a hero of the troyan war,  t  te  test of all the greek warriors, a e    the central character of homer s ']\n",
      "\n",
      "['<cls>abraham lincoln (; february 12, 1809 <unk> april 15, 1865) was an american lawyer and statesman who served as the 16th president of the united states from 1861 unt']\n",
      "['<cls>abraham lincoln (; february 12, 1809 <unk> april 15, 1865) was an american lawyer and statesman who served as the 16th president of the united stat<mask>']\n",
      "['<cls>abraham lincoln () february 12, 188<unk> <unk> april 11, 1998) was an american lawyer and statesman who served as the 18th president of the united stat   e a   e      ']\n",
      "\n",
      "['<cls>aristotle (;  aristoteles, ; 384<unk>322<unk>bc) was a greek philosopher and polymath during the classical period in ancient greece. taught by plato, he was the founde']\n",
      "['<cls>aristotle (;  a<mask>es, ; 384<unk>322<unk>bc) was a greek philosopher and polymath during the classical period in ancient greece. taught by plato, he was the founde']\n",
      "['<cls>aristotle (a  ao n   rnes, <unk> 28<unk>220 bc) was a greek philosopher and polymath during the classical period in ancient greece. taught by plato, he was the founde']\n",
      "\n",
      "['<cls>an american in paris is a jazz-influenced orchestral piece by american composer george gershwin first performed in 1928. it was inspired by the time that gersh']\n",
      "['<cls>an american in paris is<mask>influenced orchestral piece by a<mask>composer george gershwin first performed<mask>. it was inspired by the time that gersh']\n",
      "['<cls>an american in paris is        influenced orchestral piece by ae    e  composer george gershwin first performede       . it was inspired by the time that gersh']\n",
      "\n",
      "[\"<cls>the academy award for best production design recognizes achievement for art direction in film. the category's original name was best art direction, but was cha\"]\n",
      "[\"<cls>the academy award for best prod<mask>cognizes<mask> art direction in film. the category's original name was best art direction, but was cha\"]\n",
      "['<cls>the academy award for best prod      o  t    a cognibesc s   een      n art direction in film. the categoryus original name was best art direction, but was cha']\n",
      "\n",
      "['<cls>the academy awards, popularly known as the oscars, are awards for artistic and technical merit in the film industry. they are regarded by many as the most pres']\n",
      "['<cls>the academy awards, popularly known as the oscars, are awards f<mask>tic and technical merit in the film industry. th<mask>egarded by many as the m<mask>']\n",
      "['<cls>the academy awards, popularly known as the oscars, are awards f a e  e tic and technical merit in the film industry. thten  tedegarded by many as the m a      ']\n",
      "\n",
      "['<cls>actresses (catalan: actrius) is a 1997 catalan language spanish drama film produced and directed by ventura pons and based on the award-winning stage play e.r.']\n",
      "['<mask>es (cata<mask> a 1997 catalan language spanish drama film produced and<mask>d by ven<mask>sed on the award-winning stage play e.r.']\n",
      "['<cls>the  a es (catan a   a    e   a a 1999 catalan language spanish drama film produced and  n   o d by ven   e   n er     sed on the award winning stage play e.r.']\n",
      "\n",
      "[\"<cls>animalia is an illustrated children's book by graeme base. it was originally published in 1986, followed by a tenth anniversary edition in 1996, and a 25th ann\"]\n",
      "[\"<mask>a is an illustrated children's book by graeme base. it was originally published <mask> followe<mask>enth anniversary edition<mask>, and a 25th ann\"]\n",
      "['<cls>the eela is an illustrated childrenrs book by graeme base. it was originally published ai   in  foflowe   n  o enth anniversary edition   i    , and a \\n\\nth ann']\n",
      "\n",
      "['<cls>international atomic time (tai, from the french name ) is a high-precision atomic coordinate time standard based on the notional passage of proper time on eart']\n",
      "['<cls>international a<mask>e french name ) is a high-precision atom<mask>inate time stand<mask>d on the<mask>l passage of proper time on eart']\n",
      "['<cls>international a  r   n      ae        ie french name ) is a high-precision atom i  at  inate time stand     e  d on the  a    sl passase of proper time on eart']\n",
      "\n",
      "['<cls>altruism is the principle and moral practice of concern for happiness of other human beings or other animals, resulting in a quality of life both material and ']\n",
      "['<cls>altruism is the principle and moral practice of concern for happiness of other human beings or other animals, resulting in a quality of life both material and ']\n",
      "['<cls>altruism is the principle and moral practice of concern for happiness of other human beings or other animals, resulting in a uuality of life both material and ']\n",
      "\n",
      "[\"<cls>alice o'connor (born alisa zinovyevna rosenbaum; , 1905<unk> march 6, 1982), better known by her pen name ayn rand (), was a russian-born american writer and phil\"]\n",
      "[\"<cls>alice o'connor (born alisa zinovyevna rosenbaum; , 1905<unk> march 6, 1982), better known by her p<mask>ayn rand<mask>an-born american<mask>and phil\"]\n",
      "['<cls>alice occonnor (born alisa ninovvevna rosenbaum, , 1900<unk> march v, 1982), better known by her p aneea  ayn rand    aa nr  n    anbborn american  e rr nand phil']\n",
      "\n",
      "['<cls>alain connes (; born 1 april 1947) is a french mathematician, and a theoretical physicist, known for his contributions to the study of operator algebras and no']\n",
      "['<cls>alain c<mask> born 1 april 1947) is a french mathematician, and a theoretical<mask>n for hi<mask>to the study of operator algebra<mask>']\n",
      "['<cls>alain co rt loa born 1 april 199)) is a french mathematician, and a theoretical  e re    i r  an for hi             n  to the study of operator algebra e      ']\n",
      "\n",
      "['<cls>allan dwan (born joseph aloysius dwan; april 3, 1885 <unk> december 28, 1981) was a pioneering canadian-born american motion picture director, producer, and screen']\n",
      "['<cls>allan dwan (born joseph aloysius dwan; april 3, 1885 <unk> december 28, 198<mask> pioneering canadian-born american motion pictur<mask>or, producer, and screen']\n",
      "['<cls>allan dwan (born ooseph aloysius dranj april l, 1988 <unk> december 20, 19)     e   pioneering canadianoborn american motion picturr stio tor, producer, and screen']\n",
      "\n",
      "[\"<cls>algeria, officially the people's democratic republic of algeria, is a country in the maghreb region of north africa. the country is the largest country by tota\"]\n",
      "[\"<cls>algeria, offici<mask> people's democratic republic of algeria, is a country in the maghreb region of north africa. the country is the largest country by tota\"]\n",
      "['<cls>algeria, offici       t peopleps democratic republic of algeria, is a country in the maghreb region of north africa. the country is the largest country by tota']\n",
      "\n",
      "[\"<cls>this is a list of characters in ayn rand's 1957 novel atlas shrugged.\\n\\nmajor characters\\nthe following are major characters from the novel.\\n\\nprotagonists\\n\\ndagny\"]\n",
      "[\"<cls>this is a list of characters in ayn rand's 1957 novel a<mask>ugged.\\n\\nmajor ch<mask>\\nthe following are major<mask>ers from<mask>el.\\n\\nprotagonists\\n\\ndagny\"]\n",
      "['<cls>this is a list of characters in ayn randds 199) novel a  eei   ugged.\\n\\nma\\nor ch  s ntoa\\nthe following are ma\\nore     o ers fromeioeo t el\\n\\n\\nprotagonists\\n\\ndagny']\n",
      "\n",
      "--- dataset 1 ---\n",
      "\n",
      "['<cls>otothyropsis piribebuy is a species of catfish in the family loricariidae. it is native to south america, where it is known to occur in the piribebuy river and']\n",
      "['<cls>otothyr<mask>ribebuy <mask>cies of catfish in the family lo<mask>ae. it is native to south americ<mask>nown to occur in the piribebuy river and']\n",
      "['<cls>otothyr i i    ribebuy i      icies of catfish in the family looa a    ae. it is native to south americeea e  e     e  nown to occur in the piribebuy river and']\n",
      "\n",
      "['<cls>felsner is a german language habitational surname for someone who lived in a rocky place or by a cliff (fels). notable people with the name include:\\n brian fel']\n",
      "['<cls>felsner is a german language habitational surname for s<mask>ho lived in a rocky plac<mask>a cliff (fels). notable people w<mask>name inc<mask>rian fel']\n",
      "['<cls>felsner is a german language habitational surname for sl    r  ho lived in a rocyy placli   a  a cliff afels\\n. notable people w e  ae  name inc i  a   rian fel']\n",
      "\n",
      "['<cls>thakur akshay singh ratnu(b. 24 december 1910; d. 1 july 1995) was a rajasthani, brajbhasha & hindi poet from rajasthan. his penned poems criticising the briti']\n",
      "['<mask>akshay singh rat<mask>r 1910; d. 1 july 1995) was a rajasthani<mask>asha & hindi poet from rajasthan<mask>nned poems criti<mask>he briti']\n",
      "['<cls>jaraa  akshay singh rat             a ar 1910<unk> d. 1 luly 1999) was a rakasthani  a n  lasha h hindi poet from rajasthan   i  e nned poems criti        he briti']\n",
      "\n",
      "[\"<cls>the 2022 fa women's league cup final is the 11th final of the fa women's league cup, england's secondary cup competition for women's football teams and its pri\"]\n",
      "[\"<mask>2 fa women's league cup final is the 11th final of the f<mask> cup, england's <mask>y cup competition for women's football teams and its pri\"]\n",
      "['<cls>the naif fa womenss league cup final is the 19th final of the f    ee nt e      cup, englandus   ea    y cup competition for womenns football teams and its pri']\n",
      "\n",
      "['<cls>the siam rath weekly review was an english-language weekly newspaper whose first issue was published in thailand on 10 july 1952. the contents of siam rath wee']\n",
      "['<cls>the siam rath w<mask>view was an english-language weekly newspaper whose first issue was published in<mask>d on 10 july 1952. the contents of siam rath wee']\n",
      "['<cls>the siam rath w a  i   view was an englishwlanguage weeyly newspaper whose first issue was published in   r    d on 10 buly 111.. the contents of siam rath wee']\n",
      "\n",
      "['<cls>rachela suckewer or roza suckewer (1904/1905 <unk> 1943) was a polish impressionist and expressionist painter, best known for her paintings social symbol (1930) an']\n",
      "['<cls>rachela suckewer or roza suckewer (1904/1905 <unk> 1943) was a polish impressionist and expressionist painter, best known for her paintings<mask>symbol (<mask>']\n",
      "['<cls>rachela suckewer or rova suckewer (1903 1959 <unk> 1993) was a polish impressionist and eppressionist painter, best known for her paintings ra  l asymbol ,     n i']\n",
      "\n",
      "['<cls>hong kong garden may refer to:\\n\\n hong kong garden (hong kong), private housing estate in hong kong\\n hong kong garden (song), 1978 song by siouxsie and the bans']\n",
      "['<mask>ng garden may refer to:\\n\\n hong kong garden (hong kong), private housing estate in hong kong\\n hong kong garden (song), 1978 song by sioux<mask>the bans']\n",
      "['<cls>tor  n ng gargen may refer to:\\n\\n hong kong garden (hong kong), private housing estate in hong gongg hong kong garden (song,, 19 s song by sioukg  e g  the bans']\n",
      "\n",
      "['<cls>parotocinclus adamanteus is a species of catfish in the family loricariidae. it is native to south america, where it occurs in the paraguacu river basin in the']\n",
      "['<cls>parotocinclus adamanteu<mask>pecies of catfish in the family <mask>idae. it is native to south america, where it occurs in the paraguacu river basi<mask>']\n",
      "['<cls>parotocinclus adamanteun n  n  pecies of catfish in the family a  a    idae. it is native to south america, where it occurs in the paraguacu river basi     i  ']\n",
      "\n",
      "['<cls>sceloporus consobrinus, the southern prairie lizard, is a species of lizard in the family phrynosomatidae. it is found in texas, oklahoma, new mexico, arizona,']\n",
      "['<cls>sceloporus consobrinus, the southern prairie lizard, is a species of lizard in the family phrynosomatidae. it is found in texas, oklahoma, new mexico, <mask>']\n",
      "['<cls>sceloporus consobrinus, the southern prairie lirard, is a species of livard in the family phrynomomatidae. it is found in teras, ok ahoma, new me,ico, e   e   ']\n",
      "\n",
      "['<cls>arne h<unk>ygaard (15 january 1906 <unk> 16 december 1981) was a norwegian physician and arctic explorer.\\n\\nbiography \\nh<unk>ygaard was born in lillesand. after completing ']\n",
      "['<cls>arne h<unk>ygaard (<mask>ry 1906 <unk> 16 december 1981) was a norwegian physician and arctic explorer.\\n\\nbiography \\nh<mask> in lillesand. after completing ']\n",
      "['<cls>arne hhygaard (   o n ory 1988 <unk> 18 december 1991) was a norwegian physician and arccic e plorer..\\nbiography \\nh    e  e n  eaon in llllesand. after completing ']\n",
      "\n",
      "['<cls>geertruida h. springer (1895 <unk> 1988) was a dutch still life painter, best known for her paintings stilleven met fles en boek, stilleven met schedeldak en glaze']\n",
      "['<cls>geertruida h. springer (1895 <unk> 1988) wa<mask>h still life painter, best known<mask>gs still<mask> fles en boek, stilleven met schedeldak <mask>']\n",
      "['<cls>geertruida hh springer (189) <unk> 1989) wa        h still life painter, best known en i t  e      gs still         fles en boek, stilleven met schedeldak ee e    ']\n",
      "\n",
      "['<cls>nasiliu.net (no to violence) is a russian nonprofit organization founded in 2015, which supports women who experience domestic violence. its director is anna r']\n",
      "['<cls>nasiliu.net (no<mask>ence) is a russi<mask>ofit organization founde<mask>5, which supports women who experience domestic violence. its di<mask>s anna r']\n",
      "['<cls>nasiliunnet (nos       ence) is a russi   n    ofit organination founden       w, which supports women who e perience domestic violence. its di   nn  is anna r']\n",
      "\n",
      "['<cls>badreddine assouar (born may 5, 1974) is a physicist, currently director of research at cnrs and the university of lorraine in france. his research focuses on ']\n",
      "['<cls>badreddine assouar (born may 5, 1974) i<mask>icist, currently director of research at<mask>d the university of lorraine in <mask>his rese<mask>uses on ']\n",
      "['<cls>badreddine assouar (born may ,, 199)) i  an ae icist, currently director of research at e   e nd the university of lorraine in         his rese        uses on ']\n",
      "\n",
      "['<cls>elguja amashukeli  (georgian: <unk> <unk> <unk> <unk>; 22 april 1928 <unk> 10 march  2002) was a georgian sculptor and painter. from 1981 to 1996 he was the ch']\n",
      "['<cls>elguja amashukeli  (georgian: <unk><mask> <unk>; 22 a<mask>8 <unk> 10 march  2002) was <mask>an sculptor and painter. from 1981 to 1996 he was the ch']\n",
      "['<cls>elguua amashumeli  (georgian: <unk>     i <unk>   <unk> <unk> <unk> 20 a        <unk> <unk> 1) march  10000 was  ee t   an sculptor and painter. from mm91 to 199\\n he was the ch']\n",
      "\n",
      "['<cls>julia cury<unk>o (born 1986, in warsaw) is a polish painter and art critic, best known for her art installation lambs of god at the marymont metro station in warsa']\n",
      "['<cls>julia cury<unk>o (born 1986, in war<mask>a polish<mask> and art critic, best known for her art installation lambs of god at the marymont metro station in warsa']\n",
      "['<cls>julia curyyo (born 1988, in war        a polish       n and art critic, best known for her art installation lambs of fod at the marmmont metro station in warsa']\n",
      "\n",
      "['<cls>lt col inka niskanen is an officer and fighter pilot in the finnish air force. she is notable as the first woman in finland to qualify to pilot a fighter jet; ']\n",
      "['<cls>lt col inka niskanen is<mask>cer and fighter pilot in<mask>nish air force. she is notable as the first woman in finland to qualify <mask> a fight<mask>']\n",
      "['<cls>lt col inka niskanen is a   i acer and fighter pilot in        nish air force. she is notable as the first woman in finland to fualify aene   t a fight        ']\n",
      "\n",
      "['<cls>oleg anfimov (1937<unk>2019; full name: oleg grigoriyevich anfimov) was a soviet engineer and politician who was the minister of electrical equipment industry of t']\n",
      "['<cls>oleg anfimov (1937<unk>2019; full name: oleg grigoriyevich anfimov) was a soviet engineer and politician who was the minister of electrical equipment industry of t']\n",
      "['<cls>oleg anfimof ((11192019) full name, olegggrigorivevich anfimov) was a soviet engineer and politician who was the minister of electrical eduipment industry of t']\n",
      "\n",
      "['<cls>ranunculus tripartitus, three-lobed crowfoot, is a species of flowering plant in the family ranunculaceae, which grows in pools and muddy hollows in coastal pa']\n",
      "['<cls>ranunculus tripartitus, three-lobed cro<mask>s a species of f<mask> plant in the family ranunculaceae, which grows in pools<mask>dy hollows in coastal pa']\n",
      "['<cls>ranunculus tripartitusu three2lobed cro e      s a species of f  e a    plant in the family ranuuuulaceae, which grows in pools  o eno dy hollows in coastal pa']\n",
      "\n",
      "[\"<cls>sceloporus couchii, couch's spiny lizard, is a species of lizard in the family phrynosomatidae. it is endemic to mexico.\\n\\nreferences\\n\\nsceloporus\\nreptiles of me\"]\n",
      "[\"<cls>sceloporus couchii, couch's spiny lizard, is a species of lizard in the family phrynosomatidae. it is endemic to mexico.\\n\\nrefer<mask>celoporu<mask>es of me\"]\n",
      "['<cls>sceloporus couchii, couchis spiny li ard, is a species of livard in the family phrynosomatidae. it is endemic to mevico.\\n\\nrererse re e celoporu      iees of me']\n",
      "\n",
      "['<cls>pierre singaravelou (born 18 january 1977) is a french global historian who is a british academy global professor of history at king<unk>s college london. he is al']\n",
      "['<cls>pierre singaravelou (born 18 january 1977) is a<mask>global historian who is a british academ<mask> professor of history at king<unk>s college london. he is al']\n",
      "['<cls>pierre singaravelou (born 18 january 1987) is a  s  eeaglobal historian who is a british academitel   e professor of history at kingis college london. he is al']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ds_idx, ds in enumerate([dataset_train, dataset_eval]):\n",
    "    print(f\"--- dataset {ds_idx} ---\\n\")\n",
    "    for i in range(20):\n",
    "        data = collate([ds[i]])\n",
    "        # data = collate([ds[random.randint(0, len(dataset_eval) - 1)]])\n",
    "        logits = model.predict(\n",
    "            data[\"masked_labels\"].to(device), data[\"attention_mask\"].to(device)\n",
    "        )[0]\n",
    "        print(decode(data[\"labels\"].detach().tolist()))\n",
    "        print(decode(data[\"masked_labels\"].detach().tolist()))\n",
    "        print(decode(logits.argmax(axis=2).detach().tolist()))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<cls>hi, how are you? hi, how are you? hi, how are you? hi, how are you?<char_pad><eos>']\n",
      "['<cls>hir h o  r how hrh ow are y hare o <eos>   <ngram_pad>']\n",
      "\n",
      "['<cls>it seems that this can output its input pretty well, as long as the input is of a decent length, but for short sentences it seems to not be good at all, this i']\n",
      "['<cls>it seems that this can output its input pretty well, as long as the input is of a decent length, but for short sentences it seems to not be good at all, this i']\n",
      "\n",
      "['<cls>hi, how are you doin? hi, how are you? hi, how are you? hi, how are you? hi, how are you? hi, how are you? hi, how are you? hi, how are you? hi, how are you? h']\n",
      "['<cls>hihoh w aru aoe doonh h ,ihow  awe youuhi, woh re  oen  hih howra e yoioyhohih\\nw ary eooars aiaow wre y        h w areeuh h hih hoe hro yooy hih ,ow aoe ohu   ']\n",
      "\n",
      "[\"<cls>interesting, it seems to fail even for the longer input, if it's very repetitive. i wonder what's going on there. will this work better? is it more like wiki t\"]\n",
      "['<cls>interesting, it seems to fail even for the longer input, if itks very repetitive. i wonder whatgs soing on there. will this wore betterk is it more like wiki t']\n",
      "\n",
      "['<cls>alain connes (; born 1 april 1947) is a french mathematician, and a theoretical physicist, known for his contributions to the study of operator algebras and no']\n",
      "['<cls>alain connes (( born 1 april 197)) is a french mathematician, and a theoretical physicist, wnown for his contributions to the study of operator algebras and no']\n",
      "\n",
      "['<cls>peter connes (; born april fools) is a french mathematician, and a masterful physicist, known for his many many contributions to the study of operator algebras']\n",
      "['<cls>peter connes (( born april fools) is a french mathematician, and a masterful physicist, known for his many many contributions to the study of operator algebras']\n",
      "\n",
      "['<cls>hello, world!<char_pad><eos>']\n",
      "['<cls><eos><ngram_pad>']\n",
      "\n",
      "['<cls>one two three<char_pad><eos>']\n",
      "['<cls><eos><ngram_pad>']\n",
      "\n",
      "[\"<cls>the 2022 fa women's league cup<char_pad><eos>\"]\n",
      "['<cls>the  <ngram_pad>ea<ngram_pad>']\n",
      "\n",
      "['<cls>badreddine assouar (born may 5, 1974) is a physicist,<char_pad><eos>']\n",
      "['<cls>baddds (born 1 s a ppnao<eos>o<eos> <ngram_pad>']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# without masking (checking it can encode/decode input)\n",
    "examples = [\n",
    "    \"Hi, how are you? Hi, how are you? Hi, how are you? Hi, how are you?\",\n",
    "    \"it seems that this can output its input pretty well, as long as the input is of a decent length, but for short sentences it seems to not be good at all, this is very interesting\",\n",
    "    \"Hi, how are you doin? Hi, how are you? Hi, how are you? Hi, how are you? Hi, how are you? Hi, how are you? Hi, how are you? Hi, how are you? Hi, how are you? Hi, how are you? Hi, how are you? Hi, how are you?\",\n",
    "    \"Interesting, it seems to fail even for the longer input, if it's very repetitive. I wonder what's going on there. Will this work better? Is it more like wiki text? that's interesting o.O.\",\n",
    "    \"alain connes (; born 1 april 1947) is a french mathematician, and a theoretical physicist, known for his contributions to the study of operator algebras and no\",\n",
    "    \"peter connes (; born april fools) is a french mathematician, and a masterful physicist, known for his many many contributions to the study of operator algebras and no\",\n",
    "    \"Hello, world!\",\n",
    "    \"One two three\",\n",
    "    \"the 2022 fa women's league cup\",\n",
    "    \"badreddine assouar (born may 5, 1974) is a physicist,\",\n",
    "]\n",
    "for example in examples:\n",
    "    data = collate([tokenize(example)])\n",
    "    logits = model.predict(data[\"labels\"].to(device), data[\"attention_mask\"].to(device))[\n",
    "        0\n",
    "    ]\n",
    "    print(decode(data[\"labels\"].detach().tolist()))\n",
    "    print(decode(logits.argmax(axis=2).detach().tolist()))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<cls>hi, how are you? hi, how are you? hi, how are you? hi, how are you?<char_pad><eos>']\n",
      "['<cls>hi, how are you<mask>u? hi, how are you? hi, how are you?<char_pad><eos>']\n",
      "['<cls>hih how       e eh ow arely  are o <eos><ngram_pad>']\n",
      "\n",
      "['<cls>it seems that this can output its input pretty well, as long as the input is of a decent length, but for short sentences it seems to not be good at all, this i']\n",
      "['<mask>s that t<mask>output its input<mask> the input is of a decent length, but for short sentences it see<mask>t be good at all, this i']\n",
      "['<cls>the  iis that toa s    output its inputi  oen  eteett au  e     the input is of a decent length, but for short sentences it seeer  t int be good at all, this i']\n",
      "\n",
      "['<cls>hi, how are you doin? hi, how are you? hi, how are you? hi, how are you? hi, how are you? hi, how are you? hi, how are you? hi, how are you? hi, how are you? h']\n",
      "['<cls>hi, how<mask> doin? h<mask>re you? hi, how are you? hi, how are you? hi, how are you? hi, how are you? hi, how are you? hi, how are you? hi, how are you? h']\n",
      "['<cls>hihoh w  aae h  doonh hr i     are youuhi, woh re  ouoy hiv howra e yoi  hu, hhw ary eoyouh hiyow wre yyuo hi, how areeud h hih hoe arw yooy hih ,ow a e er    ']\n",
      "\n",
      "[\"<cls>interesting, it seems to fail even for the longer input, if it's very repetitive. i wonder what's going on there. will this work better? is it more like wiki t\"]\n",
      "[\"<cls>interesting, it seems to fail even for the longer input, if it's very repetitive. i won<mask> on there. will this work better? is it more like wiki t\"]\n",
      "['<cls>interesting, it seems to fail even for the longer input, if itks very repetitive. i wone  t     t o n e on there. will this work betters is it more like wiki t']\n",
      "\n",
      "['<cls>alain connes (; born 1 april 1947) is a french mathematician, and a theoretical physicist, known for his contributions to the study of operator algebras and no']\n",
      "['<cls>alain c<mask> born 1 april 1947) is a french mathematician, a<mask> physicist, known for hi<mask>butions to the study of operator<mask>']\n",
      "['<cls>alain co r  trl born 1 april 1996) is a french mathematician, a  a       a      physicist, wnown for hi      e butions to the study of operator        ti      ']\n",
      "\n",
      "['<cls>peter connes (; born april fools) is a french mathematician, and a masterful physicist, known for his many many contributions to the study of operator algebras']\n",
      "['<cls>peter connes (; born april fools) is a french mathematician, and a masterful physicist, known for his many many<mask>utions to the study of o<mask>algebras']\n",
      "['<cls>peter connes (( born april fools) is a french mathematician, and a masterful physicist, known for his many many  a     utions to the study of oa   a  ialgebras']\n",
      "\n",
      "['<cls>hello, world!<char_pad><eos>']\n",
      "['<cls>hello, world!<char_pad><eos>']\n",
      "['<cls><eos><ngram_pad>']\n",
      "\n",
      "['<cls>one two three<char_pad><eos>']\n",
      "['<cls>one two three<char_pad><eos>']\n",
      "['<cls><eos><ngram_pad>']\n",
      "\n",
      "[\"<cls>the 2022 fa women's league cup<char_pad><eos>\"]\n",
      "[\"<mask>2 fa women's league cup<char_pad><eos>\"]\n",
      "['<cls>s m  lea<ngram_pad>']\n",
      "\n",
      "['<cls>badreddine assouar (born may 5, 1974) is a physicist,<char_pad><eos>']\n",
      "['<cls>badreddine asso<mask>n may 5, 1974) is a physicist,<char_pad><eos>']\n",
      "['<cls>badr   reren 1 s a pana<eos><ngram_pad><eos><ngram_pad>']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# with masking\n",
    "for example in examples:\n",
    "    # data = collate([tokenize(example), dataset_train[40]])\n",
    "    data = collate([tokenize(example)], masking_probability=0.15)\n",
    "    # data = collate([ds[random.randint(0, len(dataset_eval) - 1)]])\n",
    "    logits = model.predict(data[\"masked_labels\"].to(device), data[\"attention_mask\"].to(device))[\n",
    "        0\n",
    "    ]\n",
    "    print(decode(data[\"labels\"].detach().tolist()))\n",
    "    print(decode(data[\"masked_labels\"].detach().tolist()))\n",
    "    print(decode(logits.argmax(axis=2).detach().tolist()))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
